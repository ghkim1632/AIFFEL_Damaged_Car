{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "import model.metric as module_metric\n",
    "\n",
    "from data_loader.dataloader import get_dataloader \n",
    "from utils.data import get_datasize\n",
    "from utils.visual import *\n",
    "from albumentations.pytorch import transforms\n",
    "from model.loss import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 1e-2\n",
    "batch_size = 4\n",
    "num_epoch = 100\n",
    "\n",
    "train_dir = './dataset/refined/crushed/train/'\n",
    "val_dir = './dataset/refined/crushed/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.Rotate((-30, 30), p=0.5, border_mode=cv2.BORDER_REFLECT,),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean = 0.5, std=0.5),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean = 0.5, std=0.5),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(train_dir, transform_train, batch_size)\n",
    "val_dataloader = get_dataloader(val_dir, transform_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(encoder_name='efficientnet-b0', encoder_weights='imagenet', in_channels=3, classes=1, activation=None)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config['Batch size'] = batch_size\n",
    "train_config['Learning Rate'] = lr\n",
    "train_config['Epochs'] = num_epoch\n",
    "\n",
    "train_config['Loss fn'] = 'Dice'\n",
    "train_config['Optimizer'] = 'SGD'\n",
    "train_config['LR Scheduler'] = 'CosineAnnealingWarmRestarts'\n",
    "train_config['Metric'] = [metric for metric in ['IOUscore', 'PixelAccuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimlim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/imlim/Aiffel/segmentation/wandb/run-20230111_084838-1qnsd6zo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/imlim/Segmentation/runs/1qnsd6zo\" target=\"_blank\">UNet</a></strong> to <a href=\"https://wandb.ai/imlim/Segmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/imlim/Segmentation/runs/1qnsd6zo?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1614f87c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='Segmentation', name='UNet', config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [getattr(module_metric, met) for met in ['IOUscore', 'PixelAccuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, criterion, metrics, optimizer, device, num_epoch, './saved',\n",
    "                                  data_loader=train_dataloader, valid_data_loader=val_dataloader,\n",
    "                                  lr_scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 0 | Train Loss : 0.96785 | Train P.A : 0.68376% | Train IOU : 0.01756 | "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Unet' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Aiffel/segmentation/train.py:129\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch : \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    128\u001b[0m start_time \u001b[39m=\u001b[39m timer()\n\u001b[0;32m--> 129\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(epoch)\n\u001b[1;32m    130\u001b[0m end_time \u001b[39m=\u001b[39m timer()\n\u001b[1;32m    131\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining Time : \u001b[39m\u001b[39m{\u001b[39;00m(end_time\u001b[39m-\u001b[39mstart_time)\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39msec\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Aiffel/segmentation/train.py:75\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mes_log[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_validation:\n\u001b[0;32m---> 75\u001b[0m     val_loss, val_pa, val_iou \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_valid_epoch(epoch)\n\u001b[1;32m     76\u001b[0m     wandb\u001b[39m.\u001b[39mlog({\u001b[39m'\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m'\u001b[39m: train_loss, \u001b[39m'\u001b[39m\u001b[39mTrain P.A\u001b[39m\u001b[39m'\u001b[39m: train_pa, \u001b[39m'\u001b[39m\u001b[39mTrain IOU\u001b[39m\u001b[39m'\u001b[39m: train_iou,\n\u001b[1;32m     77\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mVal Loss\u001b[39m\u001b[39m'\u001b[39m: val_loss, \u001b[39m'\u001b[39m\u001b[39mVal P.A\u001b[39m\u001b[39m'\u001b[39m: val_pa, \u001b[39m'\u001b[39m\u001b[39mVal IOU\u001b[39m\u001b[39m'\u001b[39m: val_iou})\n\u001b[1;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Aiffel/segmentation/train.py:114\u001b[0m, in \u001b[0;36mTrainer._valid_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    110\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(y_pred, y_test)\n\u001b[1;32m    112\u001b[0m val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m--> 114\u001b[0m met_ \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m: metric(y_pred, y_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_fn}\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m met_\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    116\u001b[0m     val_metric[key]\u001b[39m.\u001b[39mappend(value)\n",
      "File \u001b[0;32m~/Aiffel/segmentation/train.py:114\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(y_pred, y_test)\n\u001b[1;32m    112\u001b[0m val_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m--> 114\u001b[0m met_ \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m: metric(y_pred, y_test, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice) \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_fn}\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m met_\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    116\u001b[0m     val_metric[key]\u001b[39m.\u001b[39mappend(value)\n",
      "File \u001b[0;32m~/Aiffel/segmentation/model/metric.py:17\u001b[0m, in \u001b[0;36mIOUscore\u001b[0;34m(model, outputs, labels, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39msigmoid(outputs\u001b[39m.\u001b[39mfloat()) \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     16\u001b[0m outputs\u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m intersection \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlogical_and(outputs, labels)\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     20\u001b[0m union \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlogical_or(outputs, labels)\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/Torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1264\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1265\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1266\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Unet' object has no attribute 'squeeze'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33ce5649ce404f053f526c6f24093fa00e89f7475f5a3b1e2abb12dcf144a09f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
