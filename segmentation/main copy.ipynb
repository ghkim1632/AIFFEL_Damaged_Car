{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "import model.metric as module_metric\n",
    "\n",
    "from data_loader.dataloader import get_dataloader\n",
    "from utils.data import get_datasize\n",
    "from utils.visual import *\n",
    "from albumentations.pytorch import transforms\n",
    "from model.loss import *\n",
    "from train import *\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 시드고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 1e-1\n",
    "batch_size = 4\n",
    "num_epoch = 200\n",
    "damage = 'dent'\n",
    "\n",
    "train_dir = f'./dataset/{damage}/train/'\n",
    "val_dir = f'./dataset/{damage}/valid/'\n",
    "test_dir = f'./dataset/{damage}/test/'\n",
    "\n",
    "mean= None\n",
    "std= None\n",
    "image_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.Resize(image_size, image_size),\n",
    "    A.HorizontalFlip(),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.Rotate((-10, 10), p=0.5, border_mode=cv2.BORDER_REFLECT,),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.Resize(image_size, image_size),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(image_size, image_size),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(train_dir, transform_train, batch_size, True)\n",
    "val_dataloader = get_dataloader(val_dir, transform_val, batch_size, False)\n",
    "test_dataloader = get_dataloader(test_dir, transform_test, batch_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(encoder_name='efficientnet-b7', encoder_weights='imagenet', in_channels=3, classes=1, activation=None)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.9, lr=lr)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=20, T_mult=2, eta_min=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, factor=0.5, mode='min', patience=10, min_lr=1e-5)\n",
    "metrics = [getattr(module_metric, met) for met in ['IOUscore', 'PixelAccuracy']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. wandb config 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {}\n",
    "train_config['Batch size'] = batch_size\n",
    "train_config['Learning Rate'] = lr\n",
    "train_config['Epochs'] = num_epoch\n",
    "train_config['Image size'] = image_size\n",
    "\n",
    "train_config['Loss fn'] = criterion.__class__.__name__\n",
    "train_config['Optimizer'] = optimizer.__class__.__name__\n",
    "train_config['LR Scheduler'] = scheduler.__class__.__name__\n",
    "train_config['Metric'] = {str(idx+1) : metric for idx, metric in enumerate([metrics[i].__name__ for i in range(len(metrics))])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"./saved/U-Net/{'_'.join([model.__dict__['name'].split('-')[1:][0].capitalize(), model.__dict__['name'].split('-')[-1].capitalize()])}_{damage}/\"\n",
    "\n",
    "trainer = Trainer(model, criterion, metrics, optimizer, device, num_epoch, save_dir, mean, std,\n",
    "                  data_loader=train_dataloader, valid_data_loader=val_dataloader, test_data_loader=test_dataloader,\n",
    "                  lr_scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.early_stop = 30\n",
    "train_config['Early stop'] = trainer.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mimlim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/imlim/Documents/Project/Damage_Segmentation/segmentation/wandb/run-20230122_221553-17ukkea9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/imlim/U-Net/runs/17ukkea9\" target=\"_blank\">Efficientnet_B7_dent_ver2_train</a></strong> to <a href=\"https://wandb.ai/imlim/U-Net\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/imlim/U-Net/runs/17ukkea9?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f48f066dc00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=trainer.dir.split('/')[1], name=f\"{trainer.dir.split('/')[2]}_train\", config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 0 | Train Loss : 0.05193 | Train P.A : 99.08% | Train IOU : 0.00000 | Val Loss : 0.04705 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 202.40sec\n",
      "\n",
      "Epoch : 1 | Train Loss : 0.03936 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.04026 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 202.36sec\n",
      "\n",
      "Epoch : 2 | Train Loss : 0.03356 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03351 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 202.06sec\n",
      "\n",
      "Epoch : 3 | Train Loss : 0.02841 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03517 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 200.17sec\n",
      "\n",
      "Epoch : 4 | Train Loss : 0.02638 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03493 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 202.24sec\n",
      "\n",
      "Epoch : 5 | Train Loss : 0.02509 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03688 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 202.61sec\n",
      "\n",
      "Epoch : 6 | Train Loss : 0.02433 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03324 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 201.34sec\n",
      "\n",
      "Epoch : 7 | Train Loss : 0.02342 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03511 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 201.48sec\n",
      "\n",
      "Epoch : 8 | Train Loss : 0.02231 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.04141 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 202.44sec\n",
      "\n",
      "Epoch : 9 | Train Loss : 0.02116 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03534 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 203.82sec\n",
      "\n",
      "Epoch : 10 | Train Loss : 0.02053 | Train P.A : 99.21% | Train IOU : 0.00000 | Val Loss : 0.03455 | Val P.A : 99.08% | Val IOU : 0.00000 | Training Time : 200.73sec\n",
      "\n",
      "Epoch : 11 | Train Loss : 0.01674 | Train P.A : 99.27% | Train IOU : 0.00000 | Val Loss : 0.04040 | Val P.A : 99.16% | Val IOU : 0.00000 | Training Time : 203.48sec\n",
      "\n",
      "Epoch : 12 | Train Loss : 0.01461 | Train P.A : 99.45% | Train IOU : 0.00000 | Val Loss : 0.03944 | Val P.A : 99.05% | Val IOU : 0.00000 | Training Time : 203.94sec\n",
      "\n",
      "Epoch : 13 | Train Loss : 0.01391 | Train P.A : 99.50% | Train IOU : 0.00000 | Val Loss : 0.04233 | Val P.A : 99.17% | Val IOU : 0.00000 | Training Time : 202.37sec\n",
      "\n",
      "Epoch : 14 | Train Loss : 0.01327 | Train P.A : 99.51% | Train IOU : 0.00000 | Val Loss : 0.03879 | Val P.A : 99.01% | Val IOU : 0.00000 | Training Time : 201.34sec\n",
      "\n",
      "Epoch : 15 | Train Loss : 0.01113 | Train P.A : 99.58% | Train IOU : 0.00000 | Val Loss : 0.05012 | Val P.A : 99.15% | Val IOU : 0.00000 | Training Time : 204.72sec\n",
      "\n",
      "Epoch : 16 | Train Loss : 0.01001 | Train P.A : 99.62% | Train IOU : 0.00000 | Val Loss : 0.04956 | Val P.A : 99.15% | Val IOU : 0.00000 | Training Time : 204.60sec\n",
      "\n",
      "Epoch : 17 | Train Loss : 0.01006 | Train P.A : 99.63% | Train IOU : 0.00000 | Val Loss : 0.05071 | Val P.A : 99.15% | Val IOU : 0.00000 | Training Time : 200.66sec\n",
      "\n",
      "Epoch : 18 | Train Loss : 0.00853 | Train P.A : 99.67% | Train IOU : 0.00000 | Val Loss : 0.05237 | Val P.A : 99.17% | Val IOU : 0.00000 | Training Time : 188.85sec\n",
      "\n",
      "Epoch : 19 | Train Loss : 0.00785 | Train P.A : 99.70% | Train IOU : 0.00000 | Val Loss : 0.05253 | Val P.A : 99.16% | Val IOU : 0.00000 | Training Time : 190.44sec\n",
      "\n",
      "Epoch : 20 | Train Loss : 0.00798 | Train P.A : 99.70% | Train IOU : 0.00000 | Val Loss : 0.05157 | Val P.A : 99.18% | Val IOU : 0.00000 | Training Time : 202.30sec\n",
      "\n",
      "Epoch : 21 | Train Loss : 0.00829 | Train P.A : 99.70% | Train IOU : 0.00000 | Val Loss : 0.05571 | Val P.A : 99.17% | Val IOU : 0.00000 | Training Time : 202.54sec\n",
      "\n",
      "Epoch : 22 | Train Loss : 0.00722 | Train P.A : 99.72% | Train IOU : 0.00000 | Val Loss : 0.05204 | Val P.A : 99.15% | Val IOU : 0.00000 | Training Time : 202.96sec\n",
      "\n",
      "Epoch : 23 | Train Loss : 0.00736 | Train P.A : 99.72% | Train IOU : 0.00000 | Val Loss : 0.05269 | Val P.A : 99.18% | Val IOU : 0.00000 | Training Time : 202.24sec\n",
      "\n",
      "Epoch : 24 | Train Loss : 0.00715 | Train P.A : 99.73% | Train IOU : 0.00000 | Val Loss : 0.05772 | Val P.A : 99.18% | Val IOU : 0.00000 | Training Time : 198.32sec\n",
      "\n",
      "Epoch : 25 | Train Loss : 0.00650 | Train P.A : 99.75% | Train IOU : 0.00000 | Val Loss : 0.05656 | Val P.A : 99.17% | Val IOU : 0.00000 | Training Time : 187.97sec\n",
      "\n",
      "Epoch : 26 | "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Documents/Project/Damage_Segmentation/segmentation/train.py:177\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch : \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    176\u001b[0m start_time \u001b[39m=\u001b[39m timer()\n\u001b[0;32m--> 177\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_epoch(epoch)\n\u001b[1;32m    178\u001b[0m end_time \u001b[39m=\u001b[39m timer()\n\u001b[1;32m    179\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining Time : \u001b[39m\u001b[39m{\u001b[39;00m(end_time\u001b[39m-\u001b[39mstart_time)\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39msec\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Project/Damage_Segmentation/segmentation/train.py:69\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     66\u001b[0m train_metric \u001b[39m=\u001b[39m {\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m: [] \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_fn}\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> 69\u001b[0m \u001b[39mfor\u001b[39;00m batch, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_loader):\n\u001b[1;32m     70\u001b[0m     x_train \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     71\u001b[0m     y_train \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/Project/Damage_Segmentation/segmentation/data_loader/dataloader.py:53\u001b[0m, in \u001b[0;36mCustom_dataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     50\u001b[0m name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlst_image[index]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     52\u001b[0m \u001b[39m# Image dtype : uint8 / label dtype : uint8\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(Image\u001b[39m.\u001b[39;49mopen(glob\u001b[39m.\u001b[39;49mglob(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_dir \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m*\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m]))\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m label \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(glob\u001b[39m.\u001b[39mglob(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_dir \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     56\u001b[0m \u001b[39m# Let label images have only 2 values.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch/lib/python3.10/site-packages/PIL/Image.py:687\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    685\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    686\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m    688\u001b[0m \u001b[39mreturn\u001b[39;00m new\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch/lib/python3.10/site-packages/PIL/Image.py:729\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[39mif\u001b[39;00m encoder_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m args \u001b[39m==\u001b[39m ():\n\u001b[1;32m    727\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m--> 729\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    732\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/Torch/lib/python3.10/site-packages/PIL/ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m         )\n\u001b[1;32m    256\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 257\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "867dcab57263476bc7cd24a738863ae113fd3e5f85bcd4c9da88727adae00323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
