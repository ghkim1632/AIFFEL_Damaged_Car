{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation 학습에서 dfl backbone을 적용\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "import segmentation.model.metric as module_metric\n",
    "import segmentation.model.model as model\n",
    "import dfl_model.dfl_cnn as DFL\n",
    "\n",
    "from segmentation.data_loader.dataloader import get_dataloader\n",
    "from utils.data import get_datasize\n",
    "from utils.visual import *\n",
    "from albumentations.pytorch import transforms\n",
    "from segmentation.model.loss import *\n",
    "from segmentation.train import *\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 시드고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 201\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 하이퍼 파라미터 설정\n",
    "\n",
    "###### lr : 1e-2\n",
    "###### batch : 4\n",
    "###### epochs : 200\n",
    "###### loss : dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 1e-2\n",
    "batch_size = 4\n",
    "num_epoch = 200\n",
    "damage = 'spacing'\n",
    "\n",
    "\n",
    "train_dir = f'/aiffel/aiffel/final_project/dataset/accida_segmentation_dataset_v1/{damage}/train/'\n",
    "val_dir = f'/aiffel/aiffel/final_project/dataset/accida_segmentation_dataset_v1/{damage}/valid/'\n",
    "test_dir = f'/aiffel/aiffel/final_project/dataset/accida_segmentation_dataset_v1/{damage}/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "\n",
    "mean= (0.5, 0.5, 0.5)\n",
    "\n",
    "std= (0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.Resize(image_size, image_size),\n",
    "    A.HorizontalFlip(),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.Rotate((-10, 10), p=0.5, border_mode=cv2.BORDER_REFLECT,),\n",
    "    A.Normalize(mean, std),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.Resize(image_size, image_size),\n",
    "    A.Normalize(mean, std),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(image_size, image_size),\n",
    "    A.Normalize(mean, std),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(train_dir, transform_train, batch_size, True)\n",
    "val_dataloader = get_dataloader(val_dir, transform_val, batch_size, False)\n",
    "test_dataloader = get_dataloader(test_dir, transform_test, batch_size, False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFL 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg16 기반\n",
    "\n",
    "model_dfl_v = DFL.DFL_VGG16()\n",
    "model_dfl_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resnet50 기반\n",
    "\n",
    "# model_resnet = DFL.DFL_RESNET50()\n",
    "# model_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 DFL의 weight 확인\n",
    "\n",
    "for name, param in model_dfl_v.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 weight 가져오기\n",
    "\n",
    "model_dfl_v.load_state_dict(torch.load('./DFL_Model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 weight 불러온 뒤 모델의 weight 확인하기(위에와 비교해보기)\n",
    "\n",
    "for name, param in model_dfl_v.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습할 segmentation 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation 학습할 모델 불러오기\n",
    "\n",
    "model_unet = smp.Unet(encoder_name='vgg16_bn') # 이때 dfl에서 불러온 모델을 맞춰줘야한다\n",
    "model_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation 모델의 파라미터 확인하기\n",
    "\n",
    "for name, param in model_unet.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## segmentation의 weight 바꿔주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,33):\n",
    "    try:\n",
    "        model_dfl_v.conv1_conv4[i].weight\n",
    "        model_unet.encoder.features[i].weight\n",
    "    except :\n",
    "        print(f'{i} : ', model_dfl_v.conv1_conv4[i])\n",
    "        print(f'{i} : ', model_unet.encoder.features[i])\n",
    "    else :\n",
    "        model_unet.encoder.features[i].weight = model_dfl_v.conv1_conv4[i].weight\n",
    "        model_unet.encoder.features[i].bias = model_dfl_v.conv1_conv4[i].bias\n",
    "print(\"완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,model_dfl_v.conv5.__len__()):\n",
    "    try:\n",
    "        model_dfl_v.conv5[i].weight\n",
    "        model_unet.encoder.features[i+33].weight\n",
    "    except :\n",
    "        print(f'{i} : ', model_dfl_v.conv5[i])\n",
    "        print(f'{i} : ', model_unet.encoder.features[i+33])\n",
    "    else :\n",
    "        model_unet.encoder.features[i+33].weight = model_dfl_v.conv5[i].weight \n",
    "        model_unet.encoder.features[i+33].bias = model_dfl_v.conv5[i].bias \n",
    "\n",
    "\n",
    "print(\"완료!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## segmentation 모델에 weight 바뀌었는지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_unet.named_parameters():\n",
    "#     print(name)\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "criterion = DiceLoss().to(device)\n",
    "\n",
    "optimizer = optim.SGD( model_unet.parameters(), \n",
    "                        momentum=0.9, \n",
    "                        lr=lr,\n",
    "                        weight_decay = 5 * 1e-4 )\n",
    "\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer=optimizer, T_0=20, T_mult=2, eta_min=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau( optimizer=optimizer, \n",
    "                                                 factor=0.5, \n",
    "                                                 mode='min', \n",
    "                                                 patience=5, \n",
    "                                                 min_lr=1e-6 )\n",
    "\n",
    "metrics = [getattr(module_metric, met) for met in ['IOUscore', 'PixelAccuracy']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. wandb config 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {}\n",
    "train_config['Batch size'] = batch_size\n",
    "train_config['Learning Rate'] = lr\n",
    "train_config['Epochs'] = num_epoch\n",
    "train_config['Image size'] = image_size\n",
    "\n",
    "train_config['Loss fn'] = criterion.__class__.__name__\n",
    "train_config['Optimizer'] = optimizer.__class__.__name__\n",
    "train_config['LR Scheduler'] = scheduler.__class__.__name__\n",
    "train_config['Metric'] = {str(idx+1) : metric for idx, metric in enumerate([metrics[i].__name__ for i in range(len(metrics))])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"./saved/U-Net/{'_'.join({model_unet.__class__.__name__})}_{model_dfl_v.__class__.__name__}_{damage}_ver0/\"\n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer( model_unet, criterion, metrics, optimizer, device, num_epoch, save_dir, mean, std,\n",
    "                  data_loader=train_dataloader, valid_data_loader=val_dataloader, test_data_loader=test_dataloader,\n",
    "                  lr_scheduler=scheduler )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.early_stop = 30\n",
    "\n",
    "train_config['Early stop'] = trainer.early_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init( project=f\"[FINAL]_Fin_{trainer.dir.split('/')[1]}\", \n",
    "            name=f\"{model_dfl_v.__class__.__name__}_unet-weight(vgg)\", \n",
    "            config=train_config )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 학습 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8c34bf83bfc7bcd2aa6e2ab268591c38c42047be2677c81ba7101594e9edef1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
