{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, random, cv2\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "import model.metric as module_metric\n",
    "\n",
    "from data_loader.dataloader import get_dataloader \n",
    "from utils.data import get_datasize\n",
    "from utils.visual import *\n",
    "from albumentations.pytorch import transforms\n",
    "from model.loss import *\n",
    "from train import *\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epoch = 100\n",
    "\n",
    "train_dir = './dataset/refined/crushed/train/'\n",
    "val_dir = './dataset/refined/crushed/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.Rotate((-30, 30), p=0.5, border_mode=cv2.BORDER_REFLECT,),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean = 0.5, std=0.5),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])\n",
    "\n",
    "transform_val = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean = 0.5, std=0.5),\n",
    "    transforms.ToTensorV2(transpose_mask=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(train_dir, transform_train, batch_size)\n",
    "val_dataloader = get_dataloader(val_dir, transform_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(encoder_name='efficientnet-b0', encoder_weights='imagenet', in_channels=3, classes=1, activation=None)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiceBCELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config['Batch size'] = batch_size\n",
    "train_config['Learning Rate'] = lr\n",
    "train_config['Epochs'] = num_epoch\n",
    "\n",
    "train_config['Loss fn'] = 'DiceBCE'\n",
    "train_config['Optimizer'] = 'Adam'\n",
    "train_config['LR Scheduler'] = 'ReduceLROnPlateau'\n",
    "train_config['Metric'] = [metric for metric in ['IOUscore', 'PixelAccuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3iuft6mb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='Segmentation', name='UNet', config=train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [getattr(module_metric, met) for met in ['IOUscore', 'PixelAccuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, criterion, metrics, optimizer, device, num_epoch, Path('./saved/Efficient_B0'),\n",
    "                                  data_loader=train_dataloader, valid_data_loader=val_dataloader,\n",
    "                                  lr_scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 0 | Train Loss : 1.15082 | Train P.A : 93.08% | Train IOU : 0.31803 | (4, 256, 256) (4, 256, 256)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Aiffel/segmentation/train.py:150\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n\u001b[1;32m    149\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch : \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 150\u001b[0m     start_time \u001b[39m=\u001b[39m timer()\n\u001b[1;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_epoch(epoch)\n\u001b[1;32m    152\u001b[0m     end_time \u001b[39m=\u001b[39m timer()\n",
      "File \u001b[0;32m~/Aiffel/segmentation/train.py:77\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mes_log[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_validation:\n\u001b[0;32m---> 77\u001b[0m     val_loss, val_pa, val_iou \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_valid_epoch(epoch)\n\u001b[1;32m     78\u001b[0m     wandb\u001b[39m.\u001b[39mlog({\u001b[39m'\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m'\u001b[39m: train_loss, \u001b[39m'\u001b[39m\u001b[39mTrain P.A\u001b[39m\u001b[39m'\u001b[39m: train_pa, \u001b[39m'\u001b[39m\u001b[39mTrain IOU\u001b[39m\u001b[39m'\u001b[39m: train_iou,\n\u001b[1;32m     79\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mVal Loss\u001b[39m\u001b[39m'\u001b[39m: val_loss, \u001b[39m'\u001b[39m\u001b[39mVal P.A\u001b[39m\u001b[39m'\u001b[39m: val_pa, \u001b[39m'\u001b[39m\u001b[39mVal IOU\u001b[39m\u001b[39m'\u001b[39m: val_iou})\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Aiffel/segmentation/train.py:122\u001b[0m, in \u001b[0;36mTrainer._valid_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    120\u001b[0m pred_mask, target_mask \u001b[39m=\u001b[39m make_mask((torch\u001b[39m.\u001b[39msigmoid(y_pred) \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mfloat(), y_test)\n\u001b[1;32m    121\u001b[0m \u001b[39mprint\u001b[39m(pred_mask\u001b[39m.\u001b[39mshape, target_mask\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 122\u001b[0m wandb_img \u001b[39m=\u001b[39m ((x_test\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39m*\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0.5\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[39mprint\u001b[39m(wandb_img\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    125\u001b[0m pred_mask \u001b[39m=\u001b[39m pred_mask\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mtranpose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "867dcab57263476bc7cd24a738863ae113fd3e5f85bcd4c9da88727adae00323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
